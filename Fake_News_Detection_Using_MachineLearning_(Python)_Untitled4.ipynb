{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fake_News_Detection_Using_MachineLearning_(Python) Untitled4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNvw5XG0BabnK41cVvNJaY9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Fake News**\n",
        "\n",
        "Fake news is a form of news consisting of deliberate disinformation or hoaxes spread via traditional news media or online social media. Digital news has brought back and increased the usage of fake news, or yellow journalism.\n",
        "\n",
        "Yellow journalism and the yellow press are American terms for journalism and associated newspapers that present little or no legitimate well-researched news while instead using eye-catching headlines for increased sales.\n",
        "\n",
        "In this article, we will use the TfidfVectorizer and PassiveAggressive classifier to classify fake news and genuine news. \n",
        "\n",
        "TfidfVectorizer Convert a collection of raw documents to a matrix of TF-IDF features.\n",
        "\n",
        "TF(Term Frequency): The number of times a word has appeared in any document is its term frequency.\n",
        "\n",
        "IDF(Inverse data frequency):Inverse data frequency determines the weight of rare words across all documents in the corpus.\n",
        "\n",
        "A Simple Example how TfidfVectorizer works is given below"
      ],
      "metadata": {
        "id": "1zPKow-agGqr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEl0d5ZNfsmX",
        "outputId": "75ac4842-5cad-42c1-e3ae-ec31d91745a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 1)\t0.46979138557992045\n",
            "  (0, 2)\t0.5802858236844359\n",
            "  (0, 6)\t0.38408524091481483\n",
            "  (0, 3)\t0.38408524091481483\n",
            "  (0, 8)\t0.38408524091481483\n",
            "  (1, 5)\t0.5386476208856763\n",
            "  (1, 1)\t0.6876235979836938\n",
            "  (1, 6)\t0.281088674033753\n",
            "  (1, 3)\t0.281088674033753\n",
            "  (1, 8)\t0.281088674033753\n",
            "  (2, 4)\t0.511848512707169\n",
            "  (2, 7)\t0.511848512707169\n",
            "  (2, 0)\t0.511848512707169\n",
            "  (2, 6)\t0.267103787642168\n",
            "  (2, 3)\t0.267103787642168\n",
            "  (2, 8)\t0.267103787642168\n",
            "  (3, 1)\t0.46979138557992045\n",
            "  (3, 2)\t0.5802858236844359\n",
            "  (3, 6)\t0.38408524091481483\n",
            "  (3, 3)\t0.38408524091481483\n",
            "  (3, 8)\t0.38408524091481483\n",
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "#Example of TfidfVectorizer \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "corpus = [\n",
        "\n",
        "    'This is the first document.',\n",
        "\n",
        "     'This document is the second document.',\n",
        "\n",
        "     'And this is the third one.',\n",
        "\n",
        "     'Is this the first document?',\n",
        "\n",
        " ]\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "print(X)\n",
        "\n",
        "print(vectorizer.get_feature_names())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> *Note*\n",
        "\n",
        "From the output given above, we can understand that , First TfidfVectorizer counted the frequency of every word in the corpus and then it define weightage of every word in matrix.As you can see in the output after doing the Tfidf Vectorization, we have total 9 features in the output.  ie 9 columns (features) and 4 Rows (With weightage of every word)\n",
        "For example we get \"the\" word multiple times in any text, So TfidfTransformer finds out how much its contribution to the model is in the classification.\n",
        ">**PassiveAggressive classifier**\n",
        "\n",
        "The passive-aggressive algorithms are a family of algorithms for large-scale learning.\n",
        "Here it is enough to know that this algorithm remains passive for a correct classification outcome, and turns aggressive in the event of a miscalculation, updating and adjusting.\n",
        "\n",
        ">**Project (Implementation)\n",
        "Importing required libraries**\n",
        "\n"
      ],
      "metadata": {
        "id": "f9dgzPLMiOqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries \n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import itertools\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "metadata": {
        "id": "biikm6SJj8Jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Note**\n",
        "\n",
        "Numpy and Pandas used here for data manipulation and itertools module is used here to handle iterators.\n",
        "\n",
        "Itertools: Python itertools module is a collection of tools for handling iterators. Simply put, iterators are data types that can be used in a for loop. The most common iterator in Python is the list.\n",
        "\n",
        "In next step we will read datasets that we are going to use here it contains both (fake and real) news."
      ],
      "metadata": {
        "id": "ICY5orbpkTgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading the datasets \n",
        "\n",
        "df=pd.read_csv('/content/news.csv',error_bad_lines=False, engine=\"python\")\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "nKfUE6msuL2Z",
        "outputId": "b2894f38-3e26-4ddf-8ca2-ea210901a679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Skipping line 4719: unexpected end of data\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8476</td>\n",
              "      <td>You Can Smell Hillary’s Fear</td>\n",
              "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10294</td>\n",
              "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
              "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3608</td>\n",
              "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
              "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10142</td>\n",
              "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
              "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>875</td>\n",
              "      <td>The Battle of New York: Why This Primary Matters</td>\n",
              "      <td>It's primary day in New York and front-runners...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... label\n",
              "0        8476  ...  FAKE\n",
              "1       10294  ...  FAKE\n",
              "2        3608  ...  REAL\n",
              "3       10142  ...  FAKE\n",
              "4         875  ...  REAL\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** As you can see in the above output we have news title text in news and label of news (i.e. fake 0 or real 1)."
      ],
      "metadata": {
        "id": "CFe-dGeB0viu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining our features and target \n",
        "\n",
        "X=df['text']\n",
        "\n",
        "Y=df['label']\n",
        "\n",
        "#using split function \n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,Y, test_size=0.2, random_state=7)"
      ],
      "metadata": {
        "id": "mgAXgq8n0zwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note**\n",
        "\n",
        "As we know, we have to know about a text / corpus whether it is fake or real.that means our target is label (fake or real) which we will know from the features i.e. text. After that we split the data into train and test data.Training data  is used to train the model (learning of model), whereas from testing data we see how much the model has learned.\n",
        "\n"
      ],
      "metadata": {
        "id": "WEE6U3Bj07Lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing of data (tokenize and creating matrix)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.7)\n",
        "\n",
        "#preprocessing of train data\n",
        "\n",
        "tfidf_train=tfidf_vectorizer.fit_transform(x_train)\n",
        "\n",
        "#preprocessing of test data  \n",
        "\n",
        "tfidf_test=tfidf_vectorizer.transform(x_test)"
      ],
      "metadata": {
        "id": "FPg-KBy41MDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note**\n",
        "\n",
        "As we have discussed earlier, the TfidfVectorizer tokenize the data, then converts the data into a matrix form and decide the weightage of the words.(means preprocessing of data).Because the machine cannot understand the documents (doc type), it is necessary to preprocess the data (convert into matrix as we have seen in above  example of TfidfVectorizer).\n",
        "\n"
      ],
      "metadata": {
        "id": "rV8uHWRU1RaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#classifier or algorithm to learn the model\n",
        "\n",
        "passive=PassiveAggressiveClassifier(max_iter=50)\n",
        "\n",
        "passive.fit(tfidf_train,y_train)\n",
        "\n",
        "y_pred=passive.predict(tfidf_test)\n",
        "\n",
        "#accuracy of the model\n",
        "\n",
        "score=accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(score)\n",
        "\n",
        "#confusion matrix or kind of error calculation \n",
        "\n",
        "confusion_matrix(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABN2tXP61cgK",
        "outputId": "7b2a5ab2-6396-4d2e-f214-7570eab13b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9470338983050848\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[460,  25],\n",
              "       [ 25, 434]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note**\n",
        "\n",
        "Here we used passiveagressive classifier (or algorithm, it is a kind of supervised learning algorithm ) to train our model. After training of the model we tested our model.Accuracy of our model is 0.92 (ie 94 %) and from the confusion matrix we can clearly see that we have total 434 false news (0) , 480 real news (1) and (25+25) wrong prediction by model.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HRtccFDs4p2J"
      }
    }
  ]
}